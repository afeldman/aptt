"""Support Vector Machine (SVM) Classifier utilizing PyTorch and support vector regression (SVR) principles."""
 
import torch
from typing import Callable
 
from aptt.utils.device import get_best_device
from aptt.svm.kernels import linear_kernel
 
class SVM:
    """
    Support Vector Machine (SVM) Classifier utilizing PyTorch and support vector regression (SVR) principles.
    This implementation uses the dual form of the SVM optimization problem
    and allows for the use of different kernel functions.

    Example:
        >>> from aptt.svm import SVM
        >>> from aptt.svm.kernels import rbf_kernel
        >>> model = SVM(kernel=rbf_kernel, c=1.0, gamma=0.5)
         
        >>> model.fit(X_train, y_train)
        >>> predictions = model.predict(X_test)
    """
    def __init__(self, kernel:Callable[[torch.Tensor, torch.Tensor], torch.Tensor]=linear_kernel, c:float=1.0, **kernel_params):
        """Initialize the SVM classifier.
        
        Args:
            kernel (Callable): Kernel function to be used. Default is linear kernel.
            c (float): Regularization parameter. Default is 1.0.
            **kernel_params: Additional parameters for the kernel function.
        """
        self.kernel = kernel
        self.c = c
        self.alpha = None
        self.support_vectors = None
        self.support_labels = None
        self.b = None    
        self.kernel_params = kernel_params
        self.device = get_best_device()

    def __call__(self, *args, **kwds):
        """Call the SVM model to make predictions.
        This method allows the SVM instance to be called like a function.
        It first fits the model if it hasn't been fitted yet, and then makes predictions.
        
        Args:
            *args: Positional arguments for the fit method.
            **kwds: Keyword arguments for the fit method.
        
        Returns:
            torch.Tensor: Predicted labels for the input data.
 
        Example:
            >>> fit = SVM()(X_train, y_train, X_test)
        """
        self.fit(*args, **kwds)
 
    def fit(self, X: torch.Tensor, y: torch.Tensor, epochs=500, lr=1e-2) -> None:
        """Fit the SVM model to the training data.

        Args:
            X (torch.Tensor): Training data of shape (n_samples, n_features).
            y (torch.Tensor): Labels of shape (n_samples,).
            epochs (int): Number of training epochs. Default is 500.
            lr (float): Learning rate for the optimizer. Default is 1e-2.

        Returns:
            None
        """
        X = X.to(self.device)
        y = y.to(self.device).float()
        n_samples = X.shape[0]
 
        # Gram-Matrix mit dem Kernel
        K = self.kernel(X, X, **self.kernel_params).to(self.device)  # [n_samples x n_samples]

        # Lagrange-Multiplikatoren
        alpha = torch.zeros(n_samples, requires_grad=True)
 
        optimizer = torch.optim.SGD([alpha], lr=lr)
 
        for _ in range(epochs):
            optimizer.zero_grad()

            # Dual-Objective (zu maximieren)
            loss = 0.5 * torch.sum((alpha.view(-1, 1) * alpha.view(1, -1)) * (y.view(-1, 1) * y.view(1, -1)) * K) \
                   - torch.sum(alpha)

            (-loss).backward()  # Wir minimieren den loss
            optimizer.step()

            # Optional: Clipping von alpha fÃ¼r Hard-Margin SVM
            with torch.no_grad():
                alpha.clamp_(0, self.c)

        # Support-Vektoren extrahieren
        support_mask = alpha > 1e-5
        self.alpha = alpha[support_mask]
        self.support_vectors = X[support_mask]
        self.support_labels = y[support_mask]

        # Bias b berechnen        
        K_sv = self.kernel(self.support_vectors, self.support_vectors, **self.kernel_params)
        decision = (self.alpha * self.support_labels).view(1, -1) @ K_sv.T  # shape: (1, n_support)
        self.b = torch.mean(self.support_labels - decision.view(-1))
 
    def predict(self, X: torch.Tensor) -> torch.Tensor:
        """Predict the labels for the input data.
        Args:
            X (torch.Tensor): Input data of shape (n_samples, n_features).
        
        Returns:
            torch.Tensor: Predicted labels of shape (n_samples,).
        """
        assert self.alpha is not None, "Model must be fitted before prediction"
        X = X.to(self.device)
        K = self.kernel(X, self.support_vectors, **self.kernel_params).to(self.device) # [n_test x n_support]
        decision = torch.sum(self.alpha * self.support_labels * K, dim=1) + self.b
        return torch.sign(decision)
